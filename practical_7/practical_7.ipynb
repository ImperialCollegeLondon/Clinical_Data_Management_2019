{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 7: Image classification\n",
    "\n",
    "In this practical, we will continue working on the hand-written digit classification dataset, [MNIST](http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "![](mnist.png)\n",
    "\n",
    "Instead of using a K nearest neighbour or support vector machine classifier in the previous practical, we will use a convolutional neural network for the task.\n",
    "\n",
    "The two mainstream neural network libraries are [TensorFlow](https://www.tensorflow.org/) by Google and [PyTorch](https://pytorch.org/) by Facebook. We will use PyTorch for this practical. Please install the package first, following the [instruction](https://pytorch.org/get-started/locally/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries (provided)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output of the `extract_images()` function is a 4D array. The reason is that the [convolutational layer](https://pytorch.org/docs/stable/nn.html#conv2d) in Pytorch takes 4D arrays of shape $N \\times C \\times X \\times Y$ as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for loading MNIST image data (provided)\n",
    "def extract_images(f_name):\n",
    "    \"\"\" Extract the images into a 4D uint8 numpy array [index, rows, cols, 1]. \"\"\"\n",
    "    print('Extracting', f_name)\n",
    "    with gzip.open(f_name, 'rb') as f:\n",
    "        # Read file header\n",
    "        buffer = f.read(16)\n",
    "        magic, num_images, rows, cols = struct.unpack(\">IIII\", buffer)\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Invalid magic number {0} in MNIST image file {1}.'.format(magic, f_name))\n",
    "\n",
    "        # Read data\n",
    "        buffer = f.read(rows * cols * num_images)\n",
    "        data = np.frombuffer(buffer, dtype=np.uint8)\n",
    "        data = data.reshape(num_images, 1, rows, cols)\n",
    "        return data\n",
    "\n",
    "\n",
    "# Functions for loading MNIST label data (provided)\n",
    "def extract_labels(f_name):\n",
    "    \"\"\" Extract the labels into a 1D uint8 numpy vector [index,]. \"\"\"\n",
    "    print('Extracting', f_name)\n",
    "    with gzip.open(f_name, 'rb') as f:\n",
    "        # Read file header\n",
    "        buffer = f.read(8)\n",
    "        magic, num_items = struct.unpack(\">II\", buffer)\n",
    "        if magic != 2049:\n",
    "            raise ValueError('Invalid magic number {0} in MNIST label file {1}.'.format(magic, f_name))\n",
    "\n",
    "        # Read data\n",
    "        buffer = f.read(num_items)\n",
    "        data = np.frombuffer(buffer, dtype=np.uint8)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and browse data.\n",
    "\n",
    "The MNIST dataset is split into a training set (60,000 samples) and a test set (10,000 samples). In total, there are 4 files.\n",
    "\n",
    "* `train-images-idx3-ubyte.gz`: training images\n",
    "* `train-labels-idx1-ubyte.gz`: training labels\n",
    "* `t10k-images-idx3-ubyte.gz`: test images\n",
    "* `t10k-labels-idx1-ubyte.gz`: test labels\n",
    "\n",
    "#### 1.1 Load data (provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "X_train = extract_images('train-images-idx3-ubyte.gz')\n",
    "y_train = extract_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Test set\n",
    "X_test = extract_images('t10k-images-idx3-ubyte.gz')\n",
    "y_test = extract_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Print out the shapes of the four arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse data.\n",
    "\n",
    "We are going to provide you with the framework of a convolutional neural network as a starting point. However, some bits and pieces are missing, which need to be completed by you.\n",
    "\n",
    "The network provided has an architecture like this, with only very slight changes. For example, our input is of shape 28 x 28, instead of 32 x 32.\n",
    "\n",
    "![](lenet.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Build the network (provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LeNet (provided)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # Construct the layers. The layer names are corresponding to the annotations in the figure above.\n",
    "        self.C1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5), padding=2)\n",
    "        self.S2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.C3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5))\n",
    "        self.S4 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.C5 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5, 5))\n",
    "        self.F6 = nn.Linear(120, 84)\n",
    "        self.F7 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward propagation\n",
    "        x = F.relu(self.C1(x))\n",
    "        x = self.S2(x)\n",
    "        x = F.relu(self.C3(x))\n",
    "        x = self.S4(x)\n",
    "        x = F.relu(self.C5(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.F6(x))\n",
    "        x = F.relu(self.F7(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Train the neural network.\n",
    "\n",
    "During each iteration of training, load a random batch of images and labels, feed them to the network to perform stochastic gradient descent.\n",
    "\n",
    "Most of the code is there. You are supposed to fill in the part for randomly loading a batch of images.\n",
    "\n",
    "If the output is too long, you can right click and \"Enable Scrolling for Outputs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since most of you use laptops, we use CPU for training.\n",
    "device = 'cpu'\n",
    "# If some of you would like to try GPU. You can set the device to be CUDA.\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Network\n",
    "model = LeNet().to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimiser and learning rate\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "# Number of iterations for training\n",
    "num_iter = 100\n",
    "loss_curve = []\n",
    "\n",
    "# Train model\n",
    "start = time.time()\n",
    "for it in range(num_iter):\n",
    "    # Set the modules in training mode, which will have effects on certain modules, e.g. dropout or batchnorm.\n",
    "    start_iter = time.time()\n",
    "    model.train()\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "    # Your task\n",
    "    # Get a random batch of images and labels from X_train and y_train\n",
    "    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "    # image: batch_size x 1 x X x Y array\n",
    "    # label: batch_size vector\n",
    "    train_batch_size = 32\n",
    "    image, label = ... # Your task\n",
    "    \n",
    "    # Convert the batch of images and labels into PyTorch tensors on the device    \n",
    "    image, label = torch.from_numpy(image).float(), torch.from_numpy(label).long()\n",
    "    image, label = image.to(device), label.to(device)\n",
    "    output = model(image)\n",
    "\n",
    "    # The loss for the current batch\n",
    "    loss = criterion(output, label)\n",
    "        \n",
    "    # Perform stochastic gradient descent\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print information\n",
    "    loss_curve += [loss.item()]\n",
    "    print('--- Iteration {0}: training loss = {1:.4f}, {2:.4f} s ---'.format(it + 1, loss.item(), time.time() - start_iter))\n",
    "print('Training took {:.3f}s in total.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Plot the training loss curve, which is stored in the variable loss_curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Apply the model onto the full test set (provided). Do you feel that it is faster than K nearest neighbour during testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model (provided)\n",
    "start = time.time()\n",
    "model.eval()\n",
    "image = X_test\n",
    "image = torch.from_numpy(image).float()\n",
    "image = image.to(device)\n",
    "output = model(image)\n",
    "y_pred = output.argmax(dim=1, keepdim=True).numpy().flatten()\n",
    "print('Testing took {:.3f}s in total.'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Evaluate the classification accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Is the accuracy satisfactory? What would you do to improve the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
